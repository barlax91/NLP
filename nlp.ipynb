{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Dense,TextVectorization,Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à la base de données \"db_stack.db\" en utilisant la bibliothèque sqlite3\n",
    "db_stack = sq.connect(\"db_stack.db\")\n",
    "\n",
    "# Création d'un objet curseur pour exécuter des commandes SQL\n",
    "cursor = db_stack.cursor()\n",
    "\n",
    "# Exécution d'une instruction SELECT pour récupérer toutes les données de la table \"Stackoverflow\"\n",
    "cursor.execute(\"SELECT * FROM Stackoverflow\")\n",
    "\n",
    "# Récupération de tous les résultats de la requête précédente et stockage dans la variable \"results\"\n",
    "results = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataFrame à partir des données de la table \"Stackoverflow\" dans la base de données \"db_stack.db\"\n",
    "df = pd.read_sql_query(\"SELECT * FROM Stackoverflow\", db_stack)\n",
    "\n",
    "# Instanciation de l'objet TextVectorization pour vectoriser les questions de la table\n",
    "vecteur = TextVectorization(max_tokens=150_000, output_sequence_length=1300, output_mode='int')\n",
    "\n",
    "# Adaptation du modèle en utilisant les questions de la table\n",
    "vecteur.adapt(df['Questions'].values)\n",
    "\n",
    "# Vectorisation des questions en utilisant le modèle adapté\n",
    "text_vectorise = vecteur(df['Questions'].values) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(250, 1300), dtype=int64, numpy=\n",
       "array([[  4,   2, 116, ...,   0,   0,   0],\n",
       "       [105, 198, 269, ...,   0,   0,   0],\n",
       "       [268, 170, 102, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [137, 852, 692, ...,   0,   0,   0],\n",
       "       [ 68, 597, 513, ...,   0,   0,   0],\n",
       "       [  9,  41,   2, ...,   0,   0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction from_tensor_slices de Tensorflow pour créer un dataset à partir des vecteurs de textes et des étiquettes Toxic\n",
    "dataset = tf.data.Dataset.from_tensor_slices((text_vectorise, df['Toxic'].values)).cache().shuffle(60000).batch(10).prefetch(8)\n",
    "\n",
    "# On divise les données en 80% pour l'entrainement, 10% pour la validation et 10% pour les tests\n",
    "octante = int(len(dataset)*.8)\n",
    "dix = int(len(dataset)*.1)\n",
    "\n",
    "# Séparation des données en trois parties : entraînement, validation et test\n",
    "train,val,test = (dataset.take(octante),dataset.skip(octante).take(dix),dataset.skip(octante+dix).take(dix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 19s 653ms/step - loss: 0.4929 - val_loss: 0.0382\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 12s 593ms/step - loss: 0.4087 - val_loss: 0.4023\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 12s 592ms/step - loss: 0.3747 - val_loss: 0.1937\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 12s 577ms/step - loss: 0.2300 - val_loss: 0.1380\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 12s 580ms/step - loss: 0.1113 - val_loss: 0.0804\n"
     ]
    }
   ],
   "source": [
    "# Création d'un modèle de réseau de neurones séquentiel\n",
    "model = Sequential()\n",
    "\n",
    "# Ajout de couches d'embedding, de LSTM bidirectionnel, de couches densément connectées au modèle\n",
    "model.add(Embedding(150_001, 32))\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle en spécifiant l'optimiseur Adam et la fonction de perte BinaryCrossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy())\n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement avec une validation sur les données de validation\n",
    "res_train = model.fit(train, epochs=5, validation_data=val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benoit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gradio\\inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\Benoit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\Benoit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.13.2, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "# Define the function that runs the model and returns the output\n",
    "def predict(text):\n",
    "    text = vecteur([text])\n",
    "    prediction = model.predict(text)\n",
    "    return prediction\n",
    "\n",
    "# Create the Gradio app\n",
    "gr.Interface(predict, inputs=gr.inputs.Textbox(lines=2,placeholder='Entrez une question'), outputs='text',title=\"NLP Stackoverflow analyse de questions\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du model \n",
    "model.save('model_sof.h5')\n",
    "\n",
    "# Sauvegarde du vecteur\n",
    "pickle.dump({'config': vecteur.get_config(),\n",
    "             'weights': vecteur.get_weights()}\n",
    "            , open(\"monVecteur.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6585da97ad44c165dae3e71c3756fc1e35e0e74f20535e40fe5ad4f0890237"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
